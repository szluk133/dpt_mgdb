# import os
# import torchaudio
# import pymongo
# import json
# import torch
# import numpy as np
# from speechbrain.pretrained import SpeakerRecognition

# # C·∫•u h√¨nh k·∫øt n·ªëi MongoDB Atlas
# connection_string = "mongodb+srv://szluk133:sncuong2003@cluster0.dggxi.mongodb.net/"
# client = pymongo.MongoClient(connection_string)

# # Ch·ªçn ho·∫∑c t·∫°o database v√† collection
# db = client['nhom_5']
# collection = db['voice_segments']

# # Load m√¥ h√¨nh ECAPA-TDNN
# model = SpeakerRecognition.from_hparams(source="speechbrain/spkrec-ecapa-voxceleb", savedir="tmp_model")

# # H√†m ƒë·ªÉ chia file √¢m thanh th√†nh c√°c ƒëo·∫°n 1 gi√¢y v·ªõi overlap 50%
# def split_audio_sliding_window(signal, sample_rate, window_size=1.0, overlap=0.5):
#     """
#     Chia t√≠n hi·ªáu √¢m thanh th√†nh c√°c ƒëo·∫°n v·ªõi sliding window
    
#     Tham s·ªë:
#     - signal: tensor √¢m thanh ƒë·∫ßu v√†o
#     - sample_rate: t·∫ßn s·ªë l·∫•y m·∫´u
#     - window_size: k√≠ch th∆∞·ªõc c·ª≠a s·ªï theo gi√¢y (m·∫∑c ƒë·ªãnh 1 gi√¢y)
#     - overlap: ƒë·ªô ch·ªìng l·∫•p gi·ªØa c√°c ƒëo·∫°n (m·∫∑c ƒë·ªãnh 0.5 = 50%)
    
#     Tr·∫£ v·ªÅ:
#     - danh s√°ch c√°c ƒëo·∫°n √¢m thanh
#     """
#     # Chuy·ªÉn window_size v√† overlap th√†nh s·ªë m·∫´u
#     window_samples = int(window_size * sample_rate)
#     step_samples = int(window_samples * (1 - overlap))
    
#     # L·∫•y k√≠ch th∆∞·ªõc c·ªßa signal
#     signal_length = signal.shape[1]
    
#     # Kh·ªüi t·∫°o danh s√°ch ƒë·ªÉ l∆∞u c√°c ƒëo·∫°n
#     segments = []
    
#     # L·∫∑p qua signal v·ªõi k√≠ch th∆∞·ªõc c·ª≠a s·ªï v√† b∆∞·ªõc nh·∫£y
#     for start in range(0, signal_length - window_samples + 1, step_samples):
#         end = start + window_samples
#         segment = signal[:, start:end]
#         segments.append(segment)
    
#     return segments

# # H√†m tr√≠ch xu·∫•t embedding cho m·ªôt ƒëo·∫°n √¢m thanh
# def get_embedding(audio_segment):
#     embedding = model.encode_batch(audio_segment).squeeze().tolist()
#     return embedding

# # H√†m l∆∞u v√†o MongoDB Atlas
# def insert_segment_embedding(file_path, segment_index, start_time, embedding):
#     document = {
#         "file_path": file_path,
#         "segment_index": segment_index,
#         "start_time": start_time,
#         "window_size": 1.0,  # 1 gi√¢y
#         "overlap": 0.5,      # 50% overlap
#         "embedding": embedding
#     }
#     collection.insert_one(document)

# # Duy·ªát t·∫•t c·∫£ file trong th∆∞ m·ª•c
# def process_directory(folder_path):
#     for filename in os.listdir(folder_path):
#         if filename.endswith(".wav"):  # Ch·ªâ x·ª≠ l√Ω file WAV
#             file_path = os.path.join(folder_path, filename)
            
#             # ƒê·ªçc file √¢m thanh
#             signal, sample_rate = torchaudio.load(file_path)
            
#             # Chia file th√†nh c√°c ƒëo·∫°n 1 gi√¢y v·ªõi overlap 50%
#             segments = split_audio_sliding_window(signal, sample_rate)
            
#             print(f"ƒêang x·ª≠ l√Ω {filename}: Chia th√†nh {len(segments)} ƒëo·∫°n")
            
#             # X·ª≠ l√Ω t·ª´ng ƒëo·∫°n
#             for i, segment in enumerate(segments):
#                 # T√≠nh th·ªùi gian b·∫Øt ƒë·∫ßu c·ªßa ƒëo·∫°n
#                 start_time = i * 0.5  # M·ªói ƒëo·∫°n c√°ch nhau 0.5 gi√¢y v·ªõi overlap 50%
                
#                 # Tr√≠ch xu·∫•t embedding
#                 embedding = get_embedding(segment)
                
#                 # L∆∞u v√†o MongoDB
#                 insert_segment_embedding(file_path, i, start_time, embedding)
            
#             print(f"‚úÖ ƒê√£ x·ª≠ l√Ω v√† l∆∞u {len(segments)} ƒëo·∫°n t·ª´ {filename} v√†o MongoDB Atlas")

# # Ch·∫°y ch∆∞∆°ng tr√¨nh
# if __name__ == "__main__":
#     folder = "E:/NAM_4_KY_2_2025/CSDL_ƒêPT/filtered_audio"  # Th∆∞ m·ª•c ch·ª©a file √¢m thanh
#     process_directory(folder)
#     print("xong")


import os
import torchaudio
import pymongo
import json
from speechbrain.pretrained import SpeakerRecognition

# C·∫•u h√¨nh k·∫øt n·ªëi MongoDB Atlas
connection_string = "mongodb+srv://szluk133:sncuong2003@cluster0.dggxi.mongodb.net/"
client = pymongo.MongoClient(connection_string)

# Ch·ªçn ho·∫∑c t·∫°o database v√† collection
db = client['voice_embedding_db']
collection = db['voice_samples']

# Load m√¥ h√¨nh ECAPA-TDNN
model = SpeakerRecognition.from_hparams(source="speechbrain/spkrec-ecapa-voxceleb", savedir="tmp_model")

# H√†m tr√≠ch xu·∫•t embedding
def get_embedding(audio_path):
    signal, fs = torchaudio.load(audio_path)
    embedding = model.encode_batch(signal).squeeze().tolist()
    return embedding

# H√†m l∆∞u v√†o MongoDB Atlas
def insert_embedding(file_path, duration, embedding):
    document = {
        "file_path": file_path,
        "duration": duration,
        "embedding": embedding
    }
    collection.insert_one(document)

# Duy·ªát t·∫•t c·∫£ file trong th∆∞ m·ª•c
def process_directory(folder_path):
    for filename in os.listdir(folder_path):
        if filename.endswith(".wav"):  # Ch·ªâ x·ª≠ l√Ω file WAV
            file_path = os.path.join(folder_path, filename)
            duration = torchaudio.info(file_path).num_frames / torchaudio.info(file_path).sample_rate
            embedding = get_embedding(file_path)
            insert_embedding(file_path, duration, embedding)
            print(f"‚úÖ ƒê√£ l∆∞u {filename} v√†o MongoDB Atlas")

# Ch·∫°y ch∆∞∆°ng tr√¨nh
if __name__ == "__main__":
    folder = "E:/NAM_4_KY_2_2025/CSDL_ƒêPT/filtered_audio"  # Th∆∞ m·ª•c ch·ª©a file √¢m thanh
    process_directory(folder)
    print("üéØ Ho√†n th√†nh!")